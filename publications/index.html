<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Alexey Ignatiev | publications</title>
  <meta name="description" content="Alexey Ignatiev's home page.
">

  <link rel="shortcut icon" href="https://alexeyignatiev.github.io/assets/img/favicon.ico">

  <!-- <link href="https://fonts.googleapis.com/css?family=Fira+Sans:400,400i,600&display=swap&subset=cyrillic" rel="stylesheet" type='text/css'> -->
  <link href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/tonsky/FiraCode@1.207/distr/fira_code.css">
  <link rel="stylesheet" href="https://alexeyignatiev.github.io/assets/css/main.css">
  <link rel="canonical" href="https://alexeyignatiev.github.io/publications/">

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-WD64XP7');</script>
  <!-- End Google Tag Manager -->
</head>


  <body>

    
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WD64XP7"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Alexey</strong> Ignatiev
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://alexeyignatiev.github.io/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="https://alexeyignatiev.github.io/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://alexeyignatiev.github.io/publications/">publications</a>
          
        
          
            <a class="page-link" href="https://alexeyignatiev.github.io/software/">software</a>
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="https://alexeyignatiev.github.io/assets/pdf/cv.pdf">curriculum vitae</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="year">2021</h3>
<ol class="bibliography"><li>

<div id="msgcin-icml21">
  
    <span class="title">Explanations for Monotonic Classifiers</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  T. Gerspacher,
                
              
            
          
        
      
        
          
            
              
                
                  M. Cooper,
                
              
            
          
        
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">N. Narodytska</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          38th International Conference on Machine Learning (ICML 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In many classification tasks there is a requirement of monotonicity. Concretely, if all else remains constant, increasing (resp. decreasing) the value of one or more features must not decrease (resp. increase) the value of the prediction. Despite comprehensive efforts on learning monotonic classifiers, dedicated approaches for explaining monotonic classifiers are scarce and classifier-specific. This paper describes novel algorithms for the computation of one formal explanation of a (black-box) monotonic classiﬁer. These novel algorithms are polynomial (indeed linear) in the run time complexity of the classifier. Furthermore, the paper presents a practically efficient model-agnostic algorithm for enumerating formal explanations.</p>
  </span>
  
</div>
</li>
<li>

<div id="yislb-jair21">
  
    <span class="title">Learning Optimal Decision Sets and Lists with SAT</span>
    <span class="author">
      
        
          
            
              
                
                  Jinqiang Yu,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter Stuckey</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          Journal of Artificial Intelligence Research,
          
            
              vol.&thinsp;xx,
            
          
        
        
          pp.&thinsp;xxx–xxx,
        
        
          2021
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Decision sets and decision lists are two examples of the most easily explainable machine learning models. Given the renewed emphasis on explainable machine learning decisions, both of these machine learning models are increasingly attractive, combining small size and clear explainability. Here, we define size as the total number of literals in these rule-based models as opposed to earlier work that concentrates on the number of rules. In this paper, we develop approaches to computing minimum-size "perfect" decision sets and decision lists, which are perfectly accurate on the training data, and minimal in size, making use of modern SAT solving technology. We also provide a new method for determining optimal sparse alternatives, which trade off size and accuracy. The experiments in this paper demonstrate that the optimal decision sets computed by the SAT-based approach are comparable with the best heuristic methods, but much more succinct, and thus, more explainable. We contrast the size and test accuracy of optimal decisions lists versus optimal decision sets, as well as other state-of-the-art methods for determining optimal decision lists. Finally, we examine the size of average explanations generated by decision sets and decision lists.</p>
  </span>
  
</div>
</li>
<li>

<div id="ims-sat21a">
  
    <span class="title">SAT-Based Rigorous Explanations for Decision Lists</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          24th International Conference on Theory and Applications of Satisfiability Testing (SAT 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ims-sat21-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://github.com/alexeyignatiev/xdl-tool" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Decision lists (DLs) find a wide range of uses for classification problems in Machine Learning (ML), being implemented in a number of ML frameworks. DLs are often perceived as interpretable. However, building on recent results for decision trees (DTs), we argue that interpretability is an elusive goal for some DLs. As a result, for some uses of DLs, it will be important to compute (rigorous) explanations. Unfortunately, and in clear contrast with the case of DTs, this paper shows that computing explanations for DLs is computationally hard. Motivated by this result, the paper proposes propositional encodings for computing abductive explanations (AXps) and contrastive explanations (CXps) of DLs. Furthermore, the paper investigates the practical efficiency of a MARCO-like approach for enumerating explanations. The experimental results demonstrate that, for DLs used in practical settings, the use of SAT oracles offers a very efficient solution, and that complete enumeration of explanations is most often feasible.</p>
  </span>
  
</div>
</li>
<li>

<div id="kims-sat21b">
  
    <span class="title">Assessing Progress in SAT Solvers Through the Lens of Incremental SAT</span>
    <span class="author">
      
        
          
            
              
                
                  Stepan Kochemazov,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          24th International Conference on Theory and Applications of Satisfiability Testing (SAT 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>There is a wide consensus, which is supported by the hard experimental evidence of the SAT competitions, that clear progress in SAT solver performance has been observed in recent years. However, in the vast majority of practical applications of SAT, one is expected to use SAT solvers as oracles deciding a possibly large number of propositional formulas. In practice, this is often achieved through the use of incremental SAT. Given this fundamental use of SAT solvers, this paper investigates whether recent improvements in solver performance have an observable positive impact on the overall problem-solving efficiency in settings where incremental SAT is mandatory or at least expected. Our results, obtained on a number of well-known practically significant applications, suggest that most improvements made to SAT solvers in recent years have no positive impact on the overall performance when solvers are used incrementally.</p>
  </span>
  
</div>
</li>
<li>

<div id="imsns-ijcai21">
  
    <span class="title">Reasoning-Based Learning of Interpretable ML Models</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          30th International Joint Conference on Artificial Intelligence (IJCAI 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Artificial Intelligence (AI) is widely used in decision making procedures in myriads of real-world applications across important practical areas such as finance, healthcare, education, and safety critical systems. Due to its ubiquitous use in safety and privacy critical domains, it is often vital to understand the reasoning behind the AI decisions, which motivates the need for explainable AI (XAI). One of the major approaches to XAI is represented by computing so-called interpretable machine learning (ML) models, such as decision trees (DT), decision lists (DL) and decision sets (DS). These models build on the use of if-then rules and are thus deemed to be easily understandable by humans. A number of approaches have been proposed in the recent past to devising all kinds of interpretable ML models, the most prominent of which involve encoding the problem into a logic formalism, which is then tackled by invoking a reasoning or discrete optimization procedure. This paper overviews the recent advances of the reasoning and constraints based approaches to learning interpretable ML models and discusses their advantages and limitations.</p>
  </span>
  
</div>
</li>
<li>

<div id="ccimspp-date21">
  
    <span class="title">Optimizing Binary Decision Diagrams for Interpretable Machine Learning Classification</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://www.dauin.polito.it/personale/scheda/(nominativo)/gianpiero.cabodi" target="_blank">G. Cabodi</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.dauin.polito.it/personale/scheda/(nominativo)/paolo.camurati" target="_blank">P. E. Camurati</a>,
                
              
            
          
        
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.dauin.polito.it/personale/scheda/(nominativo)/marco.palena" target="_blank">M. Palena</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://www.dauin.polito.it/personale/scheda/(nominativo)/paolo.pasini" target="_blank">P. Pasini</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          Design, Automation and Test in Europe Conference (DATE 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ccimspp-date21-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Motivated by the need to understand the behaviour of complex machine learning (ML) models, there has been recent interest in learning optimal (or sub-optimal) decision trees (DTs). This interest is explained by the fact that DTs are widely regarded as interpretable by human decision makers. An alternative to DTs are Binary Decision Diagrams (BDDs), which can be deemed interpretable. Compared to DTs, and despite a fixed variable order, BDDs offer the advantage of more compact representations in practice, due to node sharing. Moreover, there is also extensive experience in the efficient manipulation of BDDs. Our work proposes preliminary inroads in two main directions: (a) proposing a SAT-based model for computing a decision tree as the smallest Reduced Ordered Binary Decision Diagram, consistent with given training data; and (b) exploring heuristic approaches for deriving sub-optimal (i.e., not minimal) ROBDDs, in order to improve the scalability of the proposed technique. The heuristic approach is related to recent work on using BDDs for classification. Whereas previous works addressed size reduction by general logic synthesis techniques, our work adds the contribution of generalized cofactors, that are a well-known compaction technique specific to BDDs, once a care (or equivalently a don’t care) set is given. Preliminary experimental results are also provided, proposing a direct comparison between optimal and sub-optimal solutions, as well as an evaluation of the impact of the proposed size reduction steps.</p>
  </span>
  
</div>
</li>
<li>

<div id="ilsms-aaai21">
  
    <span class="title">A Scalable Two Stage Approach to Computing Optimal Decision Sets</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://ed-lam.com/" target="_blank">Edward Lam</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          34th AAAI Conference on Artificial Intelligence (AAAI 2021),
          
          
            2021
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2102.01904" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ilsms-aaai21-preprint.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ilsms-aaai21-poster.pdf" target="_blank">Poster</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ilsms-aaai21-slides.pdf" target="_blank">Slides</a>]
  
  
  
    [<a href="https://github.com/alexeyignatiev/minds" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Machine learning (ML) is ubiquitous in modern life. Since it is being deployed in technologies that affect our privacy and safety, it is often crucial to understand the reasoning behind its decisions, warranting the need for explainable AI. Rule-based models, such as decision trees, decision lists, and decision sets, are conventionally deemed to be the most interpretable. Recent work uses propositional satisfiability (SAT) solving (and its optimization variants) to generate minimum-size decision sets. Motivated by limited practical scalability of these earlier methods, this paper proposes a novel approach to learn minimum-size decision sets by enumerating individual rules of the target decision set independently of each other, and then solving a set cover problem to select a subset of rules. The approach makes use of modern maximum satisfiability and integer linear programming technologies. Experiments on a wide range of publicly available datasets demonstrate the advantage of the new approach over the state of the art in SAT-based decision set learning.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2020</h3>
<ol class="bibliography"><li>

<div id="zims-ecai20">
  
    <span class="title">Branch Location Problems with Maximum Satisfiability</span>
    <span class="author">
      
        
          
            
              
                
                  Oleg Zaikin,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          24th European Conference on Artificial Intelligence (ECAI 2020),
          
            pp.&thinsp;379–386,
          
          
            2020
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://ecai2020.eu/papers/1599_paper.pdf" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/zims-ecai20-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Constrained location problems find a wide range of practical applications. Recent work showed that dedicated brute-force algorithms and greedy approach enable solutions of reasonable efficiency, for a restriction of the general constrained location problem, referred to as the branch location problem. This paper extends earlier work in several ways. First, the paper develops propositional encodings for the branch location problem. Second, given that the branch location problem is a restriction of the general constraint location problem, the paper shows that the restricted problem is still hard for NP. Third, the paper devises improved propositional encodings for the branch location problem, which in practice enable not only solving exactly a significantly larger class of problems but also effectively approximating optimal problem solutions, using state-of-the-art (complete and incomplete) Maximum Satisfiability (MaxSAT) solvers.</p>
  </span>
  
</div>
</li>
<li>

<div id="yilbs-corr20">
  
    <span class="title">Optimal Decision Lists using SAT</span>
    <span class="author">
      
        
          
            
              
                
                  Jinqiang Yu,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          CoRR abs/2010.09919,
        
        
        
          2020
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://arxiv.org/abs/2010.09919" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Decision lists are one of the most easily explainable machine learning models. Given the renewed emphasis on explainable machine learning decisions, this machine learning model is increasingly attractive, combining small size and clear explainability. In this paper, we show for the first time how to construct optimal "perfect" decision lists which are perfectly accurate on the training data, and minimal in size, making use of modern SAT solving technology. We also give a new method for determining optimal sparse decision lists, which trade off size and accuracy. We contrast the size and test accuracy of optimal decisions lists versus optimal decision sets, as well as other state-of-the-art methods for determining optimal decision lists. We also examine the size of average explanations generated by decision sets and decision lists.</p>
  </span>
  
</div>
</li>
<li>

<div id="iims-corr20">
  
    <span class="title">On Explaining Decision Trees</span>
    <span class="author">
      
        
          
            
              
                
                  Yacine Izza,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          CoRR abs/2010.11034,
        
        
        
          2020
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://arxiv.org/abs/2010.11034" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Decision trees (DTs) epitomize what have become to be known as interpretable machine learning (ML) models. This is informally motivated by paths in DTs being often much smaller than the total number of features. This paper shows that in some settings DTs can hardly be deemed interpretable, with paths in a DT being arbitrarily larger than a PI-explanation, i.e. a subset-minimal set of feature values that entails the prediction. As a result, the paper proposes a novel model for computing PI-explanations of DTs, which enables computing one PI-explanation in polynomial time. Moreover, it is shown that enumeration of PI-explanations can be reduced to the enumeration of minimal hitting sets. Experimental results were obtained on a wide range of publicly available datasets with well-known DT-learning tools, and confirm that in most cases DTs have paths that are proper supersets of PI-explanations.</p>
  </span>
  
</div>
</li>
<li>

<div id="inams-corr20">
  
    <span class="title">On Relating ’Why?’ and ’Why Not?’ Explanations</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                
                  Nicholas Asher,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          CoRR abs/2012.11067,
        
        
        
          2020
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://arxiv.org/abs/2012.11067" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Explanations of Machine Learning (ML) models often address a ’Why?’ question. Such explanations can be related with selecting feature-value pairs which are sufficient for the prediction. Recent work has investigated explanations that address a ’Why Not?’ question, i.e. finding a change of feature values that guarantee a change of prediction. Given their goals, these two forms of explaining predictions of ML models appear to be mostly unrelated. However, this paper demonstrates otherwise, and establishes a rigorous formal relationship between ’Why?’ and ’Why Not?’ explanations. Concretely, the paper proves that, for any given instance, ’Why?’ explanations are minimal hitting sets of ’Why Not?’ explanations and vice-versa. Furthermore, the paper devises novel algorithms for extracting and enumerating both forms of explanations.</p>
  </span>
  
</div>
</li>
<li>

<div id="icshms-cp20">
  
    <span class="title">Towards Formal Fairness in Machine Learning</span>
    <span class="author">
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  M. Cooper,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://homepages.laas.fr/msiala/" target="_blank">M. Siala</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://homepages.laas.fr/ehebrard/" target="_blank">E. Hebrard</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>26th International Conference on Principles and Practice of Constraint Programming (CP 2020)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;12333,
          
          
            pp.&thinsp;846–867,
          
          
            2020
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2010.09919" target="_blank">arXiv</a>]
  
  
    [<a href="https://doi.org/10.1007/978-3-030-58475-7_49" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/icshms-cp20-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>One of the challenges of deploying machine learning (ML) systems is fairness. Datasets often include sensitive features, which ML algorithms may unwittingly use to create models that exhibit unfairness. Past work on fairness offers no formal guarantees in their results. This paper proposes to exploit formal reasoning methods to tackle fairness. Starting from an intuitive criterion for fairness of an ML model, the paper formalises it, and shows how fairness can be represented as a decision problem, given some logic representation of an ML model. The same criterion can also be applied to assessing bias in training data. Moreover, we propose a reasonable set of axiomatic properties which no other definition of dataset bias can satisfy. The paper also investigates the relationship between fairness and explainability, and shows that approaches for computing explanations can serve to assess fairness of particular predictions. Finally, the paper proposes SAT-based approaches for learning fair ML models, even when the training data exhibits bias, and reports experimental trials.</p>
  </span>
  
</div>
</li>
<li>

<div id="yisb-cp20">
  
    <span class="title">Computing Optimal Decision Sets with SAT</span>
    <span class="author">
      
        
          
            
              
                
                  Jinqiang Yu,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>26th International Conference on Principles and Practice of Constraint Programming (CP 2020)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;12333,
          
          
            pp.&thinsp;952–970,
          
          
            2020
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2007.15140" target="_blank">arXiv</a>]
  
  
    [<a href="https://doi.org/10.1007/978-3-030-58475-7_55" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/yisb-cp20-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>As machine learning is increasingly used to help make decisions, there is a demand for these decisions to be explainable. Arguably, the most explainable machine learning models use decision rules. This paper focuses on decision sets, a type of model with unordered rules, which explains each prediction with a single rule. In order to be easy for humans to understand, these rules must be concise. Earlier work on generating optimal decision sets first minimizes the number of rules, and then minimizes the number of literals, but the resulting rules can often be very large. Here we consider a better measure, namely the total size of the decision set in terms of literals. So we are not driven to a small set of rules which require a large number of literals. We provide the first approach to determine minimum-size decision sets that achieve minimum empirical risk and then investigate sparse alternatives where we trade accuracy for size. By finding optimal solutions we show we can build decision set classifiers that are almost as accurate as the best heuristic methods, but far more concise, and hence more explainable.</p>
  </span>
  
</div>
</li>
<li>

<div id="ignatiev-ijcai20">
  
    <span class="title">Towards Trustable Explainable AI</span>
    <span class="author">
      
        
          
            <em>Alexey Ignatiev</em>
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          29th International Joint Conference on Artificial Intelligence (IJCAI 2020),
          
            pp.&thinsp;5154–5158,
          
          
            2020
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.24963/ijcai.2020/726" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ignatiev-ijcai20-preprint.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ignatiev-ijcai20-poster.pdf" target="_blank">Poster</a>]
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/html/ijcai20-slides/" target="_blank">Slides</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Explainable artificial intelligence (XAI) represents arguably one of the most crucial challenges being faced by the area of AI these days. Although the majority of approaches to XAI are of heuristic nature, recent work proposed the use of abductive reasoning to computing provably correct explanations for machine learning (ML) predictions. The proposed rigorous approach was shown to be useful not only for computing trustable explanations but also for validating explanations computed heuristically. It was also applied to uncover a close relationship between XAI and verification of ML models. This paper overviews the advances of the rigorous logic-based approach to XAI and argues that it is indispensable if trustable XAI is of concern.</p>
  </span>
  
</div>
</li>
<li>

<div id="msgcin-nips20">
  
    <span class="title">Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  T. Gerspacher,
                
              
            
          
        
      
        
          
            
              
                
                  M. Cooper,
                
              
            
          
        
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">N. Narodytska</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          34th Conference on Neural Information Processing Systems (NeurIPS 2020),
          
          
            2020
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2008.05803" target="_blank">arXiv</a>]
  
  
    [<a href="https://proceedings.neurips.cc/paper/2020/hash/eccd2a86bae4728b38627162ba297828-Abstract.html" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msgcin-nips20-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://github.com/jpmarquessilva/expxlc" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recent work proposed the computation of so-called PI-explanations of Naive Bayes Classifiers (NBCs). PI-explanations are subset-minimal sets of feature-value pairs that are sufficient for the prediction, and have been computed with state-of-the-art exact algorithms that are worst-case exponential in time and space. In contrast, we show that the computation of one PI-explanation for an NBC can be achieved in log-linear time, and that the same result also applies to the more general class of linear classifiers. Furthermore, we show that the enumeration of PI-explanations can be obtained with polynomial delay. Experimental results demonstrate the performance gains of the new algorithms when compared with earlier work. The experimental results also investigate ways to measure the quality of heuristic explanations.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="imms-jsat19">
  
    <span class="title">RC2: An Efficient MaxSAT Solver</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          Journal on Satisfiability, Boolean Modeling and Computation,
          
            
              vol.&thinsp;11,
            
          
        
        
          pp.&thinsp;53–64,
        
        
          2019
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://jsatjournal.org/volumes/11/" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-jsat19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://pysathq.github.io/" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recent work proposed a toolkit PySAT aiming at fast and easy prototyping with propositional satisfiability (SAT) oracles in Python, which enabled one to exploit the power of the original implementations of the state-of-the-art SAT solvers in Python. Maximum satisfiability (MaxSAT) is a well-known optimization version of SAT, which can be solved with a series of calls to a SAT oracle. Based on this fact and motivated by the ideas underlying the PySAT toolkit, this paper describes and evaluates RC2 (stands for relaxable cardinality constraints), a new core-guided MaxSAT solver written in Python, which won both unweighted and weighted categories of the main track of MaxSAT Evaluation 2018.</p>
  </span>
  
</div>
</li>
<li>

<div id="inms-aaai19">
  
    <span class="title">Abduction-Based Explanations for Machine Learning Models</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          33rd AAAI Conference on Artificial Intelligence (AAAI 2019),
          
            pp.&thinsp;1511–1519,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1811.10656" target="_blank">arXiv</a>]
  
  
    [<a href="https://aaai.org/ojs/index.php/AAAI/article/view/3964" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/inms-aaai19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/inms-aaai19-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The growing range of applications of Machine Learning (ML) in a multitude of settings motivates the ability of computing small explanations for predictions made. Small explanations are generally accepted as easier for human decision makers to understand. Most earlier work on computing explanations is based on heuristic approaches, providing no guarantees of quality, in terms of how close such solutions are from cardinality- or subset-minimal explanations. This paper develops a constraint-agnostic solution for computing explanations for any ML model. The proposed solution exploits abductive reasoning, and imposes the requirement that the ML model can be represented as sets of constraints using some target constraint reasoning system for which the decision problem can be answered with some oracle. The experimental results, obtained on well-known datasets, validate the scalability of the proposed approach as well as the quality of the computed solutions.</p>
  </span>
  
</div>
</li>
<li>

<div id="imwms-ijcai19">
  
    <span class="title">Model-Based Diagnosis with Multiple Observations</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://www.georg.weissenbacher.name/" target="_blank">Georg Weissenbacher</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          28th International Joint Conference on Artificial Intelligence (IJCAI 2019),
          
            pp.&thinsp;1108–1115,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.24963/ijcai.2019/155" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imwms-ijcai19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imwms-ijcai19-slides.pdf" target="_blank">Slides</a>]
  
  
  
    [<a href="https://github.com/alexeyignatiev/mbd-mobs" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Existing automated testing frameworks require multiple observations to be jointly diagnosed with the purpose of identifying common fault locations. This is the case for example with continuous integration tools. This paper shows that existing solutions fail to compute the set of minimal diagnoses, and as a result run times can increase by orders of magnitude. The paper proposes not only solutions to correct existing algorithms, but also conditions for improving their run times. Nevertheless, the diagnosis of multiple observations raises a number of important computational challenges, which even the corrected algorithms are often unable to cope with. As a result, the paper devises a novel algorithm for diagnosing multiple observations, which is shown to enable significant performance improvements in practice.</p>
  </span>
  
</div>
</li>
<li>

<div id="zmiums-lata19">
  
    <span class="title">Efficient Symmetry Breaking for SAT-Based Minimum DFA Inference</span>
    <span class="author">
      
        
          
            
              
                
                  I. Zakirzyanov,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">A. Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="http://rain.ifmo.ru/~ulyantsev/" target="_blank">V. Ulyantsev</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>21st International Conference on Theory and Applications of Satisfiability Testing (LATA 2019)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;11417,
          
          
            pp.&thinsp;159–173,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-030-13435-8_12" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/zmiums-lata19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Inference of deterministic finite automata (DFA) finds a wide range of important practical applications. In recent years, the use of SAT and SMT solvers for the minimum size DFA inference problem (MinDFA) enabled significant performance improvements. Nevertheless, there are many problems that are simply too difficult to solve to optimality with existing technologies. One fundamental difficulty of the MinDFA problem is the size of the search space. Moreover, another fundamental drawback of these approaches is the encoding size. This paper develops novel compact encodings for Symmetry Breaking of SAT-based approaches to MinDFA. The proposed encodings are shown to perform comparably in practice with the most efficient, but also significantly larger, symmetry breaking encodings.</p>
  </span>
  
</div>
</li>
<li>

<div id="mkims-sat19a">
  
    <span class="title">On Computing the Union of MUSes</span>
    <span class="author">
      
        
          
            
              
                
                  Carlos Mencia,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://cs.swan.ac.uk/~csoliver/" target="_blank">Oliver Kullmann</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd International Conference on Theory and Applications of Satisfiability Testing (SAT 2019)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;11628,
          
          
            pp.&thinsp;211–221,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-030-24258-9_15" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/mkims-sat19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper considers unsatisfiable CNF formulas and addresses the problem of computing the union of the clauses included in some minimally unsatisfiable subformula (MUS). The union of MUSes represents a useful notion in infeasibility analysis since it summarizes all the causes for the unsatisfiability of a given formula. The paper proposes a novel algorithm for this problem, developing a refined recursive enumeration of MUSes based on powerful pruning techniques. Experimental results indicate the practical suitability of the approach.</p>
  </span>
  
</div>
</li>
<li>

<div id="mibmsb-sat19b">
  
    <span class="title">DRMaxSAT with MaxHS: First Contact</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.cs.upc.edu/~bonet/" target="_blank">Maria Luisa Bonet</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://www.math.ucsd.edu/~sbuss/" target="_blank">Sam Buss</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd International Conference on Theory and Applications of Satisfiability Testing (SAT 2019)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;11628,
          
          
            pp.&thinsp;239–249,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-030-24258-9_17" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/mibmsb-sat19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The proof system of Dual-Rail MaxSAT (DRMaxSAT) was recently shown to be capable of efficiently refuting families of formulas that are well-known to be hard for resolution, concretely when the MaxSAT solving approach is either MaxSAT resolution or core-guided algorithms. Moreover, DRMaxSAT based on MaxSAT resolution was shown to be stronger than general resolution. Nevertheless, existing experimental evidence indicates that the use of MaxSAT algorithms based on the computation of minimum hitting sets (MHSes), i.e. MaxHS-like algorithms, are as effective, and often more effective, than core-guided algorithms and algorithms based on MaxSAT resolution. This paper investigates the use of MaxHS-like algorithms in the DRMaxSAT proof system. Concretely, the paper proves that the propositional encoding of the pigenonhole and doubled pigenonhole principles have polynomial time refutations when the DRMaxSAT proof system uses a MaxHS-like algorithm.</p>
  </span>
  
</div>
</li>
<li>

<div id="nsmims-sat19c">
  
    <span class="title">Assessing Heuristic Machine Learning Explanations with Model Counting</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.cs.rice.edu/~as128/" target="_blank">Aditya Shrotri</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.comp.nus.edu.sg/~meel/" target="_blank">Kuldeep S. Meel</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd International Conference on Theory and Applications of Satisfiability Testing (SAT 2019)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;11628,
          
          
            pp.&thinsp;267–278,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-030-24258-9_19" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/nsmims-sat19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Machine Learning (ML) models are widely used in decision making procedures in finance, medicine, education, etc. In these areas, ML outcomes can directly affect humans, e.g. by deciding whether a person should get a loan or be released from prison. Therefore, we cannot blindly rely on black box ML models and need to explain the decisions made by them. This motivated the development of a variety of ML-explainer systems, including LIME and its successor ANCHOR. Due to the heuristic nature of explanations produced by existing tools, it is necessary to validate them. We propose a SAT-based method to assess the quality of explanations produced by ANCHOR. We encode a trained ML model and an explanation for a given prediction as a propositional formula. Then, by using a state-of-the-art approximate model counter, we estimate the quality of the provided explanation as the number of solutions supporting it.</p>
  </span>
  
</div>
</li>
<li>

<div id="inms-corr19">
  
    <span class="title">On Validating, Repairing and Refining Heuristic ML Explanations</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          CoRR abs/1907.02509,
        
        
        
          2019
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://arxiv.org/abs/1907.02509" target="_blank">HTML</a>]
  
  
  
  
  
  
  
    [<a href="https://github.com/alexeyignatiev/xplainer" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recent years have witnessed a fast-growing interest in computing explanations for Machine Learning (ML) models predictions. For non-interpretable ML models, the most commonly used approaches for computing explanations are heuristic in nature. In contrast, recent work proposed rigorous approaches for computing explanations, which hold for a given ML model and prediction over the entire instance space. This paper extends earlier work to the case of boosted trees and assesses the quality of explanations obtained with state-of-the-art heuristic approaches. On most of the datasets considered, and for the vast majority of instances, the explanations obtained with heuristic approaches are shown to be inadequate when the entire instance space is (implicitly) considered.</p>
  </span>
  
</div>
</li>
<li>

<div id="inms-nips19">
  
    <span class="title">On Relating Explanations and Adversarial Examples</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          33rd Conference on Neural Information Processing
               Systems (NeurIPS 2019),
          
            pp.&thinsp;15857–15867,
          
          
            2019
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://papers.nips.cc/paper/9717-on-relating-explanations-and-adversarial-examples" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/inms-nips19-preprint.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/inms-nips19-poster.pdf" target="_blank">Poster</a>]
  
  
  
  
    [<a href="https://github.com/alexeyignatiev/xpce-duality" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The importance of explanations (XP’s) of machine learning (ML) model predictions and of adversarial examples (AE’s) cannot be overstated, with both arguably being essential for the practical success of ML in different settings. There has been recent work on understanding and assessing the relationship between XP’s and AE’s. However, such work has been mostly experimental and a sound theoretical relationship has been elusive. This paper demonstrates that explanations and adversarial examples are related by a generalized form of hitting set duality, which extends earlier work on hitting set duality observed in model-based diagnosis and knowledge compilation. Furthermore, the paper proposes algorithms, which enable computing adversarial examples from explanations and vice-versa.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="bbimsm-aaai18a">
  
    <span class="title">MaxSAT Resolution With the Dual Rail Encoding</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://www.cs.upc.edu/~bonet/" target="_blank">Maria Luisa Bonet</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.math.ucsd.edu/~sbuss/" target="_blank">Sam Buss</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          32nd AAAI Conference on Artificial Intelligence (AAAI 2018),
          
            pp.&thinsp;6565–6572,
          
          
            2018
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16782" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/bbimsm-aaai18a-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Conflict-driven clause learning (CDCL) is at the core of the success of modern SAT solvers. In terms of propositional proof complexity, CDCL has been shown as strong as general resolution. Improvements to SAT solvers can be realized either by improving existing algorithms, or by exploiting proof systems stronger than CDCL. Recent work proposed an approach for solving SAT by reduction to Horn MaxSAT. The proposed reduction coupled with MaxSAT resolution represents a new proof system, DRMaxSAT, which was shown to enable polynomial time refutations of pigeonhole formulas, in contrast with either CDCL or general resolution. This paper investigates the DRMaxSAT proof system, and shows that DRMaxSAT p-simulates general resolution, that AC0-Frege+PHP p-simulates DRMaxSAT, and that DRMaxSAT can not p-simulate AC0-Frege+PHP or the cutting planes proof system.</p>
  </span>
  
</div>
</li>
<li>

<div id="szoki-aaai18b">
  
    <span class="title">On Cryptographic Attacks Using Backdoors for SAT</span>
    <span class="author">
      
        
          
            
              
                
                  A. Semenov,
                
              
            
          
        
      
        
          
            
              
                
                  O. Zaikin,
                
              
            
          
        
      
        
          
            
              
                
                  I. Otpuschennikov,
                
              
            
          
        
      
        
          
            
              
                
                  S. Kochemazov,
                
              
            
          
        
      
        
          
            
              and <em>A. Ignatiev</em>
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          32nd AAAI Conference on Artificial Intelligence (AAAI 2018),
          
            pp.&thinsp;6641–6648,
          
          
            2018
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1803.04646" target="_blank">arXiv</a>]
  
  
    [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16855" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/szoki-aaai18b-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Propositional satisfiability (SAT) is at the nucleus of state-of-the-art approaches to a variety of computationally hard problems, one of which is cryptanalysis. Moreover, a number of practical applications of SAT can only be tackled efficiently by identifying and exploiting a subset of formula’s variables called backdoor set (or simply backdoors). This paper proposes a new class of backdoor sets for SAT used in the context of cryptographic attacks, namely guess-and-determine attacks. The idea is to identify the best set of backdoor variables subject to a statistically estimated hardness of the guess-and-determine attack using a SAT solver. Experimental results on weakened variants of the renowned encryption algorithms exhibit advantage of the proposed approach compared to the state of the art in terms of the estimated hardness of the resulting guess-and-determine attacks.</p>
  </span>
  
</div>
</li>
<li>

<div id="ipnms-ijcar18">
  
    <span class="title">A SAT-Based Approach to Learn Explainable Decision Sets</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  Filipe Pereira,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>9th International Joint Conference on Automated Reasoning (IJCAR 2018)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10900,
          
          
            pp.&thinsp;627–645,
          
          
            2018
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-94205-6_41" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ipnms-ijcar18-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The successes of machine learning in recent years have triggered a fast growing range of applications. In important settings, including safety critical applications and when transparency of decisions is paramount, accurate predictions do not suffice; one expects the machine learning model to also explain the predictions made, in forms understandable by human decision makers. Recent work proposed explainable models based on decision sets which can be viewed as unordered sets of rules, respecting some sort of rule non-overlap constraint. This paper investigates existing solutions for computing decision sets and identifies a number of drawbacks, related with rule overlap and succinctness of explanations, the accuracy of achieved results, but also the efficiency of proposed approaches. To address these drawbacks, the paper develops novel SAT-based solutions for learning decision sets. Experimental results on computing decision sets for representative datasets demonstrate that SAT enables solutions that are not only the most efficient, but also offer stronger guarantees in terms of rule non-overlap.</p>
  </span>
  
</div>
</li>
<li>

<div id="nipms-ijcai18">
  
    <span class="title">Learning Optimal Decision Trees with SAT</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://research.vmware.com/researchers/nina-narodytska" target="_blank">Nina Narodytska</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  Filipe Pereira,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          27th International Joint Conference on Artificial Intelligence (IJCAI 2018),
          
            pp.&thinsp;1362–1368,
          
          
            2018
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.24963/ijcai.2018/189" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/nipms-ijcai18-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Explanations of machine learning (ML) predictions are of fundamental importance in different settings. Moreover, explanations should be succinct, to enable easy understanding by humans.  Decision trees represent an often used approach for developing explainable ML models, motivated by the natural mapping between decision tree paths and rules. Clearly, smaller trees correlate well with smaller rules, and so one  challenge is to devise solutions for computing smallest size decision trees given training data. Although simple to formulate, the computation of smallest size decision trees turns out to be an extremely challenging computational problem, for which no practical solutions are known. This paper develops a SAT-based model for computing smallest-size decision trees given training data. In sharp contrast with past work, the proposed SAT model is shown to scale for publicly available datasets of practical interest.</p>
  </span>
  
</div>
</li>
<li>

<div id="imms-sat18">
  
    <span class="title">PySAT: A Python Toolkit for Prototyping with SAT Oracles</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>21st International Conference on Theory and Applications of Satisfiability Testing (SAT 2018)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10929,
          
          
            pp.&thinsp;428–437,
          
          
            2018
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-94144-8_26" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-sat18-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://pysathq.github.io/" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Boolean satisfiability (SAT) solvers are at the core of efficient approaches for solving a vast multitude of practical problems. Moreover, albeit targeting an NP-complete problem, SAT solvers are increasingly used for tackling problems beyond NP. Despite the success of SAT in practice, modeling with SAT and more importantly implementing SAT-based problem solving solutions is often a difficult and error-prone task. This paper proposes the PySAT toolkit, which enables fast Python-based prototyping using SAT oracles and SAT-related technology. PySAT provides a simple API for working with a few state-of-the-art SAT oracles and also integrates a number of cardinality constraint encodings, all aiming at simplifying the prototyping process. Experimental results presented in the paper show that PySAT-based implementations can be as efficient as those written in a low-level language.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="imsmp-dl17">
  
    <span class="title">Debugging EL+ Ontologies through Horn MUS Enumeration</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  Carlos Mencia,
                
              
            
          
        
      
        
          
            
              
                and <a href="http://www.inf.unibz.it/~penaloza/" target="_blank">Rafael Peñaloza</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>30th International Workshop on Description Logics (DL 2017)</i>
        </span>
        <span class="periodical">
          <i>
          CEUR Workshop Proceedings,
          
            vol.&thinsp;1879,
          
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://ceur-ws.org/Vol-1879/paper54.pdf" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imsmp-dl17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In description logics (DLs), axiom pinpointing refers to the problem of enumerating the minimal subsets of axioms from an ontology that entail a given consequence. Recent developments on axiom pinpointing for the light-weight DL EL+ are based on translating this problem into the enumeration of all minimally unsatisfiable subformulas (MUSes)of a propositional formula, and using advanced SAT-based techniques for solving it. Further optimizations have been obtained by targeting the MUS enumerator to the specific properties of the formula obtained. In this paper we describe different improvements that have been considered since the translation was first proposed. Through an empirical study, we analyse the behaviour of these techniques and how it depends on different characteristics of the original pinpointing problem, and the translated SAT formula.</p>
  </span>
  
</div>
</li>
<li>

<div id="msim-epia17">
  
    <span class="title">Horn Maximum Satisfiability: Reductions, Algorithms and Applications</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>18th EPIA Conference on Artificial Intelligence (EPIA 2017)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10423,
          
          
            pp.&thinsp;681–694,
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1705.05335" target="_blank">arXiv</a>]
  
  
    [<a href="https://doi.org/10.1007/978-3-319-65340-2_56" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msim-epia17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recent years have witnessed remarkable performance improvements in maximum satisfiability (MaxSAT) solvers. In practice, MaxSAT algorithms often target the most generic MaxSAT formulation, whereas dedicated solvers, which address specific subclasses of MaxSAT, have not been investigated. This paper shows that a wide range of optimization and decision problems are either naturally formulated as MaxSAT over Horn formulas, or permit simple encodings using HornMaxSAT. Furthermore, the paper also shows how linear time decision procedures for Horn formulas can be used for developing novel algorithms for the HornMaxSAT problem.</p>
  </span>
  
</div>
</li>
<li>

<div id="pmims-eswc17">
  
    <span class="title">Lean Kernels in Description Logics</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="http://www.inf.unibz.it/~penaloza/" target="_blank">Rafael Peñaloza</a>,
                
              
            
          
        
      
        
          
            
              
                
                  Carlos Mencia,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>14th European Semantic Web Conference (ESWC 2017)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10249,
          
          
            pp.&thinsp;518–533,
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-58068-5_32" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/pmims-eswc17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Lean kernels (LKs) are an effective optimization for deriving the causes of unsatisfiability of a propositional formula.  Interestingly, no analogous notion exists for explaining consequences of description logic (DL) ontologies. We introduce LKs for DLs using a general notion of consequence-based methods, and provide an algorithm for computing them which incurs in only a linear time overhead. As an example, we instantiate our framework to the DL ALC. We prove formally and empirically that LKs provide a tighter approximation of the set of relevant axioms for a consequence than syntactic locality-based modules.</p>
  </span>
  
</div>
</li>
<li>

<div id="pijms-ictai17">
  
    <span class="title">On Computing Generalized Backbones</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://www.cs.helsinki.fi/u/mjarvisa/" target="_blank">Matti Järvisalo</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          29th International Conference on Tools with Artificial Intelligence (ICTAI 2017),
          
            pp.&thinsp;1050–1056,
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1109/ICTAI.2017.00161" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/pijms-ictai17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The concept of backbone variables, i.e., variables that take the same value in all solutions-or, equivalently, never take a specific value-finds various important applications in the context of Boolean satisfiability (SAT), motivating the development of efficient algorithms for determining the set of backbone variables of a given propositional formula. Notably, this problem surpasses the complexity of merely deciding satisfiability. In this work we consider generalizations of the concept of backbones in SAT to non-binary (and potentially infinite) domain constraint satisfaction problems. Specifically, we propose a natural generalization of backbones to the context of satisfiability modulo theories (SMT), applicable to a range of different theories as well as CSPs in general, and provide two generic algorithms for determining the backbone in this general context. As two concrete instantiations, we focus on two central SMT theories, the theory of linear integer arithmetic (LIA) with infinite integer domains, and the theory of bit vectors (BV), and empirically evaluate the potential of the proposed algorithms on both LIA and BV instances.</p>
  </span>
  
</div>
</li>
<li>

<div id="imms-ijcai17">
  
    <span class="title">Cardinality Encodings for Graph Optimization Problems</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          26th International Joint Conference on Artificial Intelligence (IJCAI 2017),
          
            pp.&thinsp;652–658,
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.24963/ijcai.2017/91" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-ijcai17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-ijcai17-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Different optimization problems defined on graphs find application in complex network analysis. Existing propositional encodings render impractical the use of propositional satisfiability (SAT) and maximum satisfiability (MaxSAT) solvers for solving a variety of these problems on large graphs. This paper has two main contributions. First, the paper identifies sources of inefficiency in existing encodings for different optimization problems in graphs. Second, for the concrete case of the maximum clique problem, the paper develops a novel encoding which is shown to be far more compact than existing encodings for large sparse graphs. More importantly, the experimental results show that the proposed encoding enables existing SAT solvers to compute a maximum clique for large sparse networks, often more efficiently than the state of the art.</p>
  </span>
  
</div>
</li>
<li>

<div id="imms-sat17">
  
    <span class="title">On Tackling the Limits of Resolution in SAT Solving</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>20th International Conference on Theory and Applications of Satisfiability Testing (SAT 2017)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10491,
          
          
            pp.&thinsp;164–183,
          
          
            2017
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1705.01477" target="_blank">arXiv</a>]
  
  
    [<a href="https://doi.org/10.1007/978-3-319-66263-3_11" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-sat17-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-sat17-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The practical success of Boolean Satisfiability (SAT) solvers stems from the CDCL (Conflict-Driven Clause Learning) approach to SAT solving. However, from a propositional proof complexity perspective, CDCL is no more powerful than the resolution proof system, for which many hard examples exist. This paper proposes a new problem transformation, which enables reducing the decision problem for formulas in conjunctive normal form (CNF) to the problem of solving maximum satisfiability over Horn formulas. Given the new transformation, the paper proves a polynomial bound on the number of MaxSAT resolution steps for pigeonhole formulas. This result is in clear contrast with earlier results on the length of proofs of MaxSAT resolution for pigeonhole formulas. The paper also establishes the same polynomial bound in the case of modern core-guided MaxSAT solvers. Experimental results, obtained on CNF formulas known to be hard for CDCL SAT solvers, show that these can be efficiently solved with modern MaxSAT solvers.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2016</h3>
<ol class="bibliography"><li>

<div id="amimpms-sat16b">
  
    <span class="title">BEACON: An Efficient SAT-Based Tool for Debugging EL+ Ontologies</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://cs.uiowa.edu/people/m-fareed-arif" target="_blank">M. F. Arif</a>,
                
              
            
          
        
      
        
          
            
              
                
                  C. Mencia,
                
              
            
          
        
      
        
          
            
              
                <em>A. Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://iccl.inf.tu-dresden.de/web/Norbert_Manthey/en" target="_blank">N. Manthey</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://www.inf.unibz.it/~penaloza/" target="_blank">R. Peñaloza</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">J. Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>19th International Conference on Theory and Applications of Satisfiability Testing (SAT 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9710,
          
          
            pp.&thinsp;521–530,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-40970-2_32" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/amimpms-sat16b-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Description Logics (DLs) are knowledge representation and reasoning formalisms used in many settings. Among them, the EL family of DLs stands out due to the availability of polynomial-time inference algorithms and its ability to represent knowledge from domains such as medical informatics. However, the construction of an ontology is an error-prone process which often leads to unintended inferences. This paper presents the BEACON tool for debugging EL+ ontologies. BEACON builds on earlier work relating minimal justifications (MinAs) of EL+ ontologies and MUSes of a Horn formula, and integrates state-of-the-art algorithms for solving different function problems in the SAT domain.</p>
  </span>
  
</div>
</li>
<li>

<div id="ijms-cj16">
  
    <span class="title">Quantified maximum satisfiability</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~mikolas/" target="_blank">Mikolas Janota</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          Constraints,
          
            
              vol.&thinsp;21(2),
            
          
        
        
          pp.&thinsp;277–302,
        
        
          2016
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/s10601-015-9195-9" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ijms-cj16-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In recent years, there have been significant improvements in algorithms both for Quantified Boolean Formulas (QBF) and for Maximum Satisfiability (MaxSAT). This paper studies an optimization extension of QBF and considers the problem in a quantified MaxSAT setting. More precisely, the general QMaxSAT problem is defined for QBFs with a set of soft clausal constraints and consists in finding the largest subset of the soft constraints such that the remaining QBF is true. Two approaches are investigated. One is based on relaxing the soft clauses and performing an iterative search on the cost function. The other approach, which is the main contribution of the paper, is inspired by recent work on MaxSAT, and exploits the iterative identification of unsatisfiable cores. The paper investigates the application of these approaches to the two concrete problems of computing smallest minimal unsatisfiable subformulas (SMUS) and smallest minimal equivalent subformulas (SMES), decision versions of which are well-known problems in the second level of the polynomial hierarchy. Experimental results, obtained on representative problem instances, indicate that the core-guided approach for the SMUS and SMES problems outperforms the use of iterative search over the values of the cost function. More significantly, the core-guided approach to SMUS also outperforms the state-of-the-art SMUS extractor Digger.</p>
  </span>
  
</div>
</li>
<li>

<div id="ipms-cp16a">
  
    <span class="title">On Finding Minimum Satisfying Assignments</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd International Conference on Principles and Practice of Constraint Programming (CP 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9892,
          
          
            pp.&thinsp;287–297,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-44953-1_19" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ipms-cp16a-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ipms-cp16a-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Given a Satisfiability Modulo Theories (SMT) formula, a minimum satisfying assignment (MSA) is a partial assignment of minimum size that ensures the formula is satisfied. Minimum satisfying assignments find a number of practical applications that include software and hardware verification, among others. Recent work proposes the use of branch-and-bound search for computing MSAs. This paper proposes a novel counterexample-guided implicit hitting set approach for computing one MSA. Experimental results show significant performance gains over existing approaches.</p>
  </span>
  
</div>
</li>
<li>

<div id="szmjin-cp16b">
  
    <span class="title">On Incremental Core-Guided MaxSAT Solving</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://www.seas.upenn.edu/~xsi/" target="_blank">Xujie Si</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://people.csail.mit.edu/xzhang/" target="_blank">Xin Zhang</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~vmm/" target="_blank">Vasco Manquinho</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~mikolas/" target="_blank">Mikolas Janota</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://www.cis.upenn.edu/~mhnaik/" target="_blank">Mayur Naik</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd International Conference on Principles and Practice of Constraint Programming (CP 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9892,
          
          
            pp.&thinsp;473–482,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-44953-1_30" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/szmjin-cp16b-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/szmjin-cp16b-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper aims to improve the efficiency of unsat core-guided MaxSAT solving on a sequence of similar problem instances. In particular, we consider the case when the sequence is constructed by adding new hard or soft clauses. Our approach is akin to the well-known idea of incremental SAT solving. However, we show that there are important differences between incremental SAT and incremental MaxSAT, where a straightforward implementation may lead to a sharp decrease in performance. We present alternatives that enable to cope with such issues. The presented algorithm is implemented and evaluated on practical problems. It solves more instances and yields an average speedup of 1.8× on previously solvable instances.</p>
  </span>
  
</div>
</li>
<li>

<div id="imms-ecai16">
  
    <span class="title">Propositional Abduction with Implicit Hitting Sets</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>22nd European Conference on Artificial Intelligence (ECAI 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Frontiers in Artificial Intelligence and Applications,
          
            vol.&thinsp;285,
          
          
            pp.&thinsp;1327–1335,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1604.08229" target="_blank">arXiv</a>]
  
  
    [<a href="https://doi.org/10.3233/978-1-61499-672-9-1327" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-ecai16-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Logic-based abduction finds important applications in artificial intelligence and related areas. One application example is in finding explanations for observed phenomena. Propositional abduction is a restriction of abduction to the propositional domain, and complexity-wise is in the second level of the polynomial hierarchy. Recent work has shown that exploiting implicit hitting sets and propositional satisfiability (SAT) solvers provides an efficient approach for propositional abduction. This paper investigates this earlier work and proposes a number of algorithmic improvements. These improvements are shown to yield exponential reductions in the number of SAT solver calls. More importantly, the experimental results show significant performance improvements compared to the the best approaches for propositional abduction.</p>
  </span>
  
</div>
</li>
<li>

<div id="msimp-jelia16">
  
    <span class="title">Efficient Reasoning for Inconsistent Horn Formulae</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  Carlos Mencia,
                
              
            
          
        
      
        
          
            
              
                and <a href="http://www.inf.unibz.it/~penaloza/" target="_blank">Rafael Peñaloza</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>15th European Conference On Logics In Artificial Intelligence (JELIA 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;10021,
          
          
            pp.&thinsp;336–352,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-48758-8_22" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msimp-jelia16-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Horn formulae are widely used in different settings that include logic programming, answer set programming, description logics, deductive databases, and system verification, among many others. One concrete example is concept subsumption in lightweight description logics, which can be reduced to inference in propositional Horn formulae. Some problems require one to reason with inconsistent Horn formulae. This is the case when providing minimal explanations of inconsistency. This paper proposes efficient algorithms for a number of decision, function and enumeration problems related with inconsistent Horn formulae. Concretely, the paper develops efficient algorithms for finding and enumerating minimal unsatisfiable subsets (MUSes), minimal correction subsets (MCSes), but also for computing the lean kernel. The paper also shows the practical importance of some of the proposed algorithms.</p>
  </span>
  
</div>
</li>
<li>

<div id="mipms-sat16a">
  
    <span class="title">MCS Extraction with Sublinear Oracle Queries</span>
    <span class="author">
      
        
          
            
              
                
                  Carlos Mencia,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>19th International Conference on Theory and Applications of Satisfiability Testing (SAT 2016)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9710,
          
          
            pp.&thinsp;342–360,
          
          
            2016
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-40970-2_21" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/mipms-sat16a-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Given an inconsistent set of constraints, an often studied problem is to compute an irreducible subset of the constraints which, if relaxed, enable the remaining constraints to be consistent. In the case of unsatisfiable propositional formulas in conjunctive normal form, such irreducible sets of constraints are referred to as Minimal Correction Subsets (MCSes). MCSes find a growing number of applications, including the approximation of maximum satisfiability and as an intermediate step in the enumeration of minimal unsatisfiability. A number of efficient algorithms have been proposed in recent years, which exploit a wide range of insights into the MCS extraction problem. One open question is to find the best worst-case number of calls to a SAT oracle, when the calls to the oracle are kept simple, and given reasonable definitions of simple SAT oracle calls. This paper develops novel algorithms for computing MCSes which, in specific settings, are guaranteed to require asymptotically fewer than linear calls to a SAT oracle, where the oracle calls can be viewed as simple. The experimental results, obtained on existing problem instances, demonstrate that the new algorithms contribute to improving the state of the art.</p>
  </span>
  
</div>
</li>
<li>

<div id="impms-aicom16">
  
    <span class="title">Maximal falsifiability</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://web.udl.es/usuaris/m4372594/" target="_blank">Jordi Planes</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          AI Commun.,
          
            
              vol.&thinsp;29(2),
            
          
        
        
          pp.&thinsp;351–370,
        
        
          2016
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3233/AIC-150685" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/impms-aicom16-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Similarly to Maximum Satisfiability (MaxSAT), Minimum Satisfiability (MinSAT) is an optimization extension of the Boolean Satisfiability (SAT) decision problem. In recent years, both problems have been studied in terms of exact and approximation algorithms. In addition, the MaxSAT problem has been characterized in terms of Maximal Satisfiable Subsets (MSSes) and Minimal Correction Subsets (MCSes), as well as Minimal Unsatisfiable Subsets (MUSes) and minimal hitting set dualization. However, and in contrast with MaxSAT, no such characterizations exist for MinSAT. This paper addresses this issue by casting the MinSAT problem in a more general framework. The paper studies Maximal Falsifiability, the problem of computing a subset-maximal set of clauses that can be simultaneously falsified, and shows that MinSAT corresponds to the complement of a largest subset-maximal set of simultaneously falsifiable clauses, i.e. the solution of the Maximum Falsifiability (MaxFalse) problem. Additional contributions of the paper include novel algorithms for Maximum and Maximal Falsifiability, as well as minimal hitting set dualization results for the MaxFalse problem. Moreover, the proposed algorithms are validated on practical instances.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2015</h3>
<ol class="bibliography"><li>

<div id="iplms-cp15">
  
    <span class="title">Smallest MUS Extraction with Minimal Hitting Set Dualization</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                
                  Mark H. Liffiton,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>21st International Conference on Principles and Practice of Constraint Programming (CP 2015)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9255,
          
          
            pp.&thinsp;173–182,
          
          
            2015
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-23219-5_13" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/iplms-cp15-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Minimal explanations of infeasibility are of great interest in many domains. In propositional logic, these are referred to as Minimal Unsatisfiable Subsets (MUSes). An unsatisfiable formula can have multiple MUSes, some of which provide more insights than others. Different criteria can be considered in order to identify a good minimal explanation. Among these, the size of an MUS is arguably one of the most intuitive. Moreover, computing the smallest MUS (SMUS) finds several practical applications that include validating the quality of the MUSes computed by MUS extractors and finding equivalent subformulae of smallest size, among others. This paper develops a novel algorithm for computing a smallest MUS, and we show that it outperforms all the previous alternatives pushing the state of the art in SMUS solving. Although described in the context of propositional logic, the presented technique can also be applied to other constraint systems.</p>
  </span>
  
</div>
</li>
<li>

<div id="msjim-ijcai15a">
  
    <span class="title">Efficient Model Based Diagnosis with Maximum Satisfiability</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~mikolas/" target="_blank">Mikolas Janota</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          24th International Joint Conference on Artificial Intelligence (IJCAI 2015),
          
            pp.&thinsp;1966–1972,
          
          
            2015
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://ijcai.org/Abstract/15/279" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msjim-ijcai15a-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msjim-ijcai15a-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Model-Based Diagnosis (MBD) finds a growing number of uses in different settings, which include software fault localization, debugging of spreadsheets, web services, and hardware designs, but also the analysis of biological systems, among many others. Motivated by these different uses, there have been significant improvements made to MBD algorithms in recent years. Nevertheless, the analysis of larger and more complex systems motivates further improvements to existing approaches. This paper proposes a novel encoding of MBD into maximum satisfiability (MaxSAT). The new encoding builds on recent work on using Propositional Satisfiability (SAT) for MBD, but identifies a number of key optimizations that are very effective in practice. The paper also proposes a new set of challenging MBD instances, which can be used for evaluating new MBD approaches. Experimental results obtained on existing and on the new MBD problem instances, show conclusive performance gains over the current state of the art.</p>
  </span>
  
</div>
</li>
<li>

<div id="pimms-ijcai15b">
  
    <span class="title">Prime Compilation of Non-Clausal Formulae</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          24th International Joint Conference on Artificial Intelligence (IJCAI 2015),
          
            pp.&thinsp;1980–1988,
          
          
            2015
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://ijcai.org/Abstract/15/281" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/pimms-ijcai15b-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Formula compilation by generation of prime implicates or implicants finds a wide range of applications in AI. Recent work on formula compilation by prime implicate/implicant generation often assumes a Conjunctive/Disjunctive Normal Form (CNF/DNF) representation. However, in many settings propositional formulae are naturally expressed in non-clausal form. Despite a large body of work on compilation of non-clausal formulae, in practice existing approaches can only be applied to fairly small formulae, containing at most a few hundred variables. This paper describes two novel approaches for the compilation of non-clausal formulae either with prime implicants or implicates, that is based on propositional Satisfiability (SAT) solving. These novel algorithms also find application when computing all prime implicates of a CNF formula. The proposed approach is shown to allow the compilation of non-clausal formulae of size significantly larger than existing approaches.</p>
  </span>
  
</div>
</li>
<li>

<div id="ipms-sat15">
  
    <span class="title">SAT-Based Formula Simplification</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://sites.google.com/view/apreviti/" target="_blank">Alessandro Previti</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>18th International Conference on Theory and Applications of Satisfiability Testing (SAT 2015)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;9340,
          
          
            pp.&thinsp;287–298,
          
          
            2015
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-24318-4_21" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ipms-sat15-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The problem of propositional formula minimization can be traced to the mid of the last century, to the seminal work of Quine and McCluskey, with a large body of work ensuing from this seminal work. Given a set of implicants (or implicates) of a formula, the goal for minimization is to find a smallest set of prime implicants (or implicates) equivalent to the original formula. This paper considers the more general problem of computing a smallest prime representation of a non-clausal propositional formula, which we refer to as formula simplification. Moreover, the paper proposes a novel, entirely SAT-based, approach for the formula simplification problem. The original problem addressed by the Quine-McCluskey procedure can thus be viewed as a special case of the problem addressed in this paper. Experimental results, obtained on well-known representative problem instances, demonstrate that a SAT-based approach for formula simplification is a viable alternative to existing implementations of the Quine-McCluskey procedure.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2014</h3>
<ol class="bibliography"><li>

<div id="mims-jsat14">
  
    <span class="title">MSCG: Robust Core-Guided MaxSAT Solving</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      <span class="periodical">
        <i>
        
          Journal on Satisfiability, Boolean Modeling and Computation,
          
            
              vol.&thinsp;9,
            
          
        
        
          pp.&thinsp;129–134,
        
        
          2014
        
        </i>
      </span>
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="http://satassociation.org/jsat/index.php/jsat/article/view/127" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/mims-jsat14-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Maximum Satisfiability (MaxSAT) is a well-known optimization version of Propositional Satisfiability (SAT) that finds a wide range of relevant practical applications. This work describes and evaluates the Maximum Satisfiability using the Core-Guided approach solver (MSCG), which is a robust MaxSAT solver that participated in the MaxSAT Evaluation 2014. An experimental comparison with state-of-the-art MaxSAT solvers is presented.</p>
  </span>
  
</div>
</li>
<li>

<div id="immlms-ecai14b">
  
    <span class="title">Progression in Maximum Satisfiability</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~vmm/" target="_blank">Vasco Manquinho</a>,
                
              
            
          
        
      
        
          
            
              
                
                  Inês Lynce,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>21st European Conference on Artificial Intelligence (ECAI 2014)</i>
        </span>
        <span class="periodical">
          <i>
          Frontiers in Artificial Intelligence and Applications,
          
            vol.&thinsp;263,
          
          
            pp.&thinsp;453–458,
          
          
            2014
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3233/978-1-61499-419-0-453" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/immlms-ecai14b-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Maximum Satisfiability (MaxSAT) is a well-known optimization version of Propositional Satisfiability (SAT), that finds a wide range of relevant practical applications. Despite the significant progress made in MaxSAT solving in recent years, many practically relevant problem instances require prohibitively large run times, and many cannot simply be solved with existing algorithms. One approach for solving MaxSAT is based on iterative SAT solving, which may optionally be guided by unsatisfiable cores. A difficulty with this class of algorithms is the possibly large number of times a SAT solver is called, e.g. for instances with very large clause weights. This paper proposes the use of geometric progressions to tackle this issue, thus allowing, for the vast majority of problem instances, to reduce the number of calls to the SAT solver. The new approach is also shown to be applicable to core-guided MaxSAT algorithms. Experimental results, obtained on a large number of problem instances, show gains when compared to state-of-the-art implementations of MaxSAT algorithms.</p>
  </span>
  
</div>
</li>
<li>

<div id="msimml-ecai14a">
  
    <span class="title">Efficient Autarkies</span>
    <span class="author">
      
        
          
            
              
                
                  <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>,
                
              
            
          
        
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~vmm/" target="_blank">Vasco Manquinho</a>,
                
              
            
          
        
      
        
          
            
              
                and Inês Lynce
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>21st European Conference on Artificial Intelligence (ECAI 2014)</i>
        </span>
        <span class="periodical">
          <i>
          Frontiers in Artificial Intelligence and Applications,
          
            vol.&thinsp;263,
          
          
            pp.&thinsp;603–608,
          
          
            2014
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.3233/978-1-61499-419-0-603" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/msimml-ecai14a-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Autarkies are partial truth assignments that satisfy all clauses having literals in the assigned variables. Autarkies provide important information in the analysis of unsatisfiable formulas. Indeed, clauses satisfied by autarkies cannot be included in minimal explanations or in minimal corrections of unsatisfiability. Computing the maximum autarky allows identifying all such clauses. In recent years, a number of alternative approaches have been proposed for computing a maximum autarky. This paper develops new models for representing autarkies, and proposes new algorithms for computing the maximum autarky. Experimental results, obtained on a large number of problem instances, show orders of magnitude performance improvements over existing approaches, and solving instances that could not otherwise be solved.</p>
  </span>
  
</div>
</li>
<li>

<div id="ijms-icse14">
  
    <span class="title">Towards efficient optimization in package management systems</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~mikolas/" target="_blank">Mikolas Janota</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>
          36th International Conference on Software Engineering (ICSE 2014),
          
            pp.&thinsp;745–755,
          
          
            2014
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1145/2568225.2568306" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ijms-icse14-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ijms-icse14-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Package management as a means of reuse of software artifacts has become extremely popular, most notably in Linux distributions. At the same time, successful package management brings about a number of computational challenges. Whenever a user requires a new package to be installed, a package manager not only installs the new package but it might also install other packages or uninstall some old ones in order to respect dependencies and conflicts of the packages. Coming up with a new configuration of packages is computationally challenging. It is in particular complex when we also wish to optimize for user preferences, such as that the resulting package configuration should not differ too much from the original one. A number of exact approaches for solving this problem have been proposed in recent years. These approaches, however, do not have guaranteed runtime due to the high computational complexity of the problem. This paper addresses this issue by devising a hybrid approach that integrates exact solving with approximate solving by invoking the approximate part whenever the solver is running out of time. Experimental evaluation shows that this approach enables returning high-quality package configurations with rapid response time.</p>
  </span>
  
</div>
</li>
<li>

<div id="imms-sat14">
  
    <span class="title">On Reducing Maximum Independent Set to Minimum Satisfiability</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>17th International Conference on Theory and Applications of Satisfiability Testing (SAT 2014)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;8561,
          
          
            pp.&thinsp;103–120,
          
          
            2014
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-319-09284-3_9" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-sat14-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/imms-sat14-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Maximum Independent Set (MIS) is a well-known NP-hard graph problem, tightly related with other well known NP-hard graph problems, namely Minimum Vertex Cover (MVC) and Maximum Clique (MaxClq). This paper introduces a novel reduction of MIS into Minimum Satisfiability (MinSAT), thus, providing an alternative approach for solving MIS. The reduction naturally maps the vertices of a graph into clauses, without requiring the inclusion of hard clauses. Moreover, it is shown that the proposed reduction uses fewer variables and clauses than the existing alternative of mapping MIS into Maximum Satisfiability (MaxSAT). The paper develops a number of optimizations to the basic reduction, which significantly reduce the total number of variables used. The experimental evaluation considered the reductions described in the paper as well as existing state-of-the-art approaches. The results show that the proposed approaches based on MinSAT are competitive with existing approaches.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2013</h3>
<ol class="bibliography"><li>

<div id="impms-lpar13">
  
    <span class="title">Maximal Falsifiability: Definitions, Algorithms, and Applications</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="https://reason.di.fc.ul.pt/wiki/doku.php?id=antonio.morgado" target="_blank">Antonio Morgado</a>,
                
              
            
          
        
      
        
          
            
              
                
                  <a href="http://web.udl.es/usuaris/m4372594/" target="_blank">Jordi Planes</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>19th International Conference on Logic for Programming Artificial Intelligence and Reasoning (LPAR 2013)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;8312,
          
          
            pp.&thinsp;439–456,
          
          
            2013
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-642-45221-5_30" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/impms-lpar13-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/impms-lpar13-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Similarly to Maximum Satisfiability (MaxSAT), Minimum Satisfiability (MinSAT) is an optimization extension of the Boolean Satisfiability (SAT) decision problem. In recent years, both problems have been studied in terms of exact and approximation algorithms. In addition, the MaxSAT problem has been characterized in terms ofMaximal Satisfiable Subsets (MSSes) andMinimal Correction Subsets (MCSes), as well as Minimal Unsatisfiable Subsets (MUSes) and minimal hitting set dualization. However, and in contrast with MaxSAT, no such characterizations exist for MinSAT. This paper addresses this issue by casting the MinSAT problem in a more general framework. The paper studies Maximal Falsifiability, the problem of computing a subset-maximal set of clauses that can be simultaneously falsified, and shows that MinSAT corresponds to the complement of a largest subset-maximal set of simultaneously falsifiable clauses, i.e. the solution of the Maximum Falsifiability (MaxFalse) problem. Additional contributions of the paper include novel algorithms for Maximum and Maximal Falsifiability, as well as minimal hitting set dualization results for the MaxFalse problem. Moreover, the proposed algorithms are validated on practical instances.</p>
  </span>
  
</div>
</li>
<li>

<div id="ijms-sat13">
  
    <span class="title">Quantified Maximum Satisfiability: A Core-Guided Approach</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>,
              
            
          
        
      
        
          
            
              
                
                  <a href="http://sat.inesc-id.pt/~mikolas/" target="_blank">Mikolas Janota</a>,
                
              
            
          
        
      
        
          
            
              
                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>16th International Conference on Theory and Applications of Satisfiability Testing (SAT 2013)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;7962,
          
          
            pp.&thinsp;250–266,
          
          
            2013
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-642-39071-5_19" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ijms-sat13-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/ijms-sat13-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In recent years, there have been significant improvements in algorithms both for Quantified Boolean Formulas (QBF) and for Maximum Satisfiability (MaxSAT). This paper studies the problem of solving quantified formulas subject to a cost function, and considers the problem in a quantified MaxSAT setting. Two approaches are investigated. One is based on relaxing the soft clauses and performing a linear search on the cost function. The other approach, which is the main contribution of the paper, is inspired by recent work on MaxSAT, and exploits the iterative identification of unsatisfiable cores. The paper investigates the application of these approaches to the concrete problem of computing smallest minimal unsatisfiable subformulas (SMUS), a decision version of which is a well-known problem in the second level of the polynomial hierarchy. Experimental results, obtained on representative problem instances, indicate that the core-guided approach for the SMUS problem outperforms the use of linear search over the values of the cost function. More significantly, the core-guided approach also outperforms the state-of-the-art SMUS extractor Digger.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2011</h3>
<ol class="bibliography"><li>

<div id="is-sat11">
  
    <span class="title">DPLL+ROBDD Derivation Applied to Inversion of Some Cryptographic
               Functions</span>
    <span class="author">
      
        
          
            
              
                <em>Alexey Ignatiev</em>
              
            
          
        
      
        
          
            
              
                and Alexander A. Semenov
              
            
          
        
      
    </span>

    
      
        <span class="periodical">
          <i>14th International Conference on Theory and Applications of Satisfiability Testing (SAT 2011)</i>
        </span>
        <span class="periodical">
          <i>
          Lecture Notes in Computer Science,
          
            vol.&thinsp;6695,
          
          
            pp.&thinsp;76–89,
          
          
            2011
          
          </i>
        </span>
      
    
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org/10.1007/978-3-642-21581-0_8" target="_blank">HTML</a>]
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/is-sat11-preprint.pdf" target="_blank">PDF</a>]
  
  
  
  
    [<a href="https://alexeyignatiev.github.io/assets/pdf/is-sat11-talk.pdf" target="_blank">Slides</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The paper presents logical derivation algorithms that can be applied to inversion of polynomially computable discrete functions. The proposed approach is based on the fact that it is possible to organize DPLL derivation on a small subset of variables appeared in a CNF which encodes the algorithm computing the function. The experimental results showed that arrays of conflict clauses generated by this mode of derivation, as a rule, have efficient ROBDD representations. This fact is the departing point of development of a hybrid DPLL+ROBDD derivation strategy: derivation techniques for ROBDD representations of conflict databases are the same as those ones in common DPLL (variable assignments and unit propagation). In addition, compact ROBDD representations of the conflict databases can be shared effectively in a distributed computing environment.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <!-- <footer> -->

<!--   <div class="wrapper"> -->
<!--     &copy; Copyright 2021 Alexey Ignatiev. -->
<!--     Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
 -->
<!--      -->
<!--   </div> -->

<!-- </footer> -->


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://alexeyignatiev.github.io/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://alexeyignatiev.github.io/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://alexeyignatiev.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://alexeyignatiev.github.io/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-43206589-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
